{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42e7b6-e266-4f94-a083-09459ff29254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FutureWarning: is_categorical is deprecated and will be removed in a future version.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273689f5-4b5a-4a4d-aeeb-b5142e5442da",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "Load training data from a CSV file. dataset.   \n",
    "Note that we loaded data from a CSV file stored in the cloud (AWS s3 bucket), but you can you specify a local file-path instead if you have already downloaded the CSV file to your own machine (e.g., using wget). Each row in the table train_data corresponds to a single training example.\n",
    "\n",
    "### Pandas\n",
    "pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dd9d2-1240-476c-aca7-04a3e6f5490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_train = pd.read_csv('./titanic/train.csv')\n",
    "df_test = pd.read_csv('./titanic/test.csv')\n",
    "\n",
    "target_col = 'Survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72312e-fa41-40cf-b477-a02531f26ab7",
   "metadata": {},
   "source": [
    "### DataFrame.head\n",
    "Returns the first n rows.  \n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2943b-a542-4148-96c7-686bc9b7d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07ec5f-e600-474f-aec8-640aa00fe0d3",
   "metadata": {},
   "source": [
    "## Automated Dataset Overview\n",
    "Automated dataset overview allows you to easily get a high-level understanding of datasets, including information about the number of rows and columns, the data types of each column, and basic statistical information about the number of rows and columns, the data types of each column and basic statistical information such as min/max values, mean, quartiles, and standard deviation. This functionality can be a valuable tool for quickly identifying potential issues or areas of interest in your dataset before diving deeper into your analysis.\n",
    "\n",
    "The last chart is a feature distance. It measures the similarity between features in a dataset. For example, if two variables are almost identical, their feature distance will be small. Understanding feature distance is useful in feature selection, where it can be used to identify which variables are redundant and should be considered to removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23103acf-0def-4687-8516-ba3ad757d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon.eda.auto as auto\n",
    "\n",
    "auto.dataset_overview(train_data=df_train, test_data=df_test, label=target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1c861-6626-4792-8fe8-b0d14f345722",
   "metadata": {},
   "source": [
    "## Covariate Shift Analysis\n",
    "Covariate shift is a phenomenon in machine learning where the distribution of the independent variables in the training and testing data is different. This can occur when the training data and testing data come from different sources, regions or changes over time. This can result in biased model performance, as the model is not generalizing well to the test data.\r\n",
    "\r\n",
    "To address covariate shift, various techniques can be used, such as re-sampling the data, adjusting the model to account for the shift, transforming the data to a form not exposed to the shift (i.e. car year make -> car age) or obtaining additional data to balance the distribution of the independent variables. The goal is to ensure that the model is trained and tested on similar data distributions, so that the model is generalizing well when deployed into productio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923e15e-3006-4083-804e-f9877d49dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.covariate_shift_detection(train_data=df_train, test_data=df_test, label=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066fbef-5fe0-4e8a-9243-8fac492fe5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns='PassengerId')\n",
    "df_test = df_test.drop(columns='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10154c01-9d94-40ab-b5d8-c8718a993ed9",
   "metadata": {},
   "source": [
    "## \n",
    "Feature Interaction Chartin\n",
    "This tool is made for quick interactions visualization between variables in a dataset. User can specify the variables to be plotted on the x, y and hue (color) parameters. The tool automatically picks chart type to render based on the detected variable types and renders 1/2/3-way interactions.\n",
    "\n",
    "This feature can be useful in exploring patterns, trends, and outliers and potentially identify good predictors for the task. \n",
    "g\n",
    "### Missing value analysis\n",
    "\n",
    "Analyze dataset's missing value counts and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d47fed-1ca9-46dd-8b8a-763b37cb3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.missing_values_analysis(train_data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9fdb47-608e-43f0-bc74-3d16c17f520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_median(df,variable):\n",
    "    df[variable+'_mean']  = df[variable].fillna(df[variable].mean())\n",
    "    df[variable+'_median']  = df[variable].fillna(df[variable].median())\n",
    "\n",
    "# mean_median(df_train,'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30693c-d304-4776-b776-99661777183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train.Embarked.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee39048-f0cb-42d2-a8a8-bd996e85a39a",
   "metadata": {},
   "source": [
    "It looks like there are only two null values in the Embarked feature. \n",
    "We may be able to fill these by looking at other independent. Both passengers paid a Fare of $80 are in the C Embarked values where Pclass is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee89f8-f867-41c7-8361-5ab763b84d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.analyze_interaction(train_data=df_train, x='Embarked', y='Fare', hue='Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d0b41-42a1-4321-86ea-13654ac653a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.analyze_interaction(x='Age', hue='Survived', train_data=df_train, test_data=df_test)     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbcc083c-3cb4-4c1d-a6c5-080686c15d4c",
   "metadata": {},
   "source": [
    "## Predicting Columns in a Table\n",
    "\n",
    "Via a simple fit() call, AutoGluon can produce highly-accurate models to predict the values in one column of a data table based on the rest of the column's values. Use AutoGluon with tabular data for both classification and regression problems.  \n",
    "\n",
    "https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html\r\n",
    "## Description of fit():\n",
    "Here we discuss what happened during fit().\r\n",
    "\r\n",
    "Since there are only two possible values of the class variable, this was a binary classification problem, for which an appropriate performance metric is accuracy. AutoGluon automatically infers this as well as the type of each feature (i.e., which columns contain continuous numbers vs. discrete categories). AutoGluon can also automatically handle common issues like missing data and rescaling feature values.\r\n",
    "\r\n",
    "We did not specify separate validation data and so AutoGluon automatically choses a random training/validation split of the data. The data used for validation is seperated from the training data and is used to determine the models and hyperparameter-values that produce the best results. Rather than just a single model, AutoGluon trains multiple models and ensembles them together to ensure superior predictive performance.\r\n",
    "\r\n",
    "By default, AutoGluon tries to fit various types of models including neural networks and tree ensembles. Each type of model has various hyperparameters, which traditionally, the user would have to specify. AutoGluon automates this process.\r\n",
    "\r\n",
    "AutoGluon automatically and iteratively tests values for hyperparameters to produce the best performance on the validation data. This involves repeatedly training models under different hyperparameter settings and evaluating their performance. This process can be computationally-intensive, so fit() can parallelize this process across multiple threads (and machines if distributed resources are available). To control runtimes, you can specify various arguments .d classes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49869dac-9bf1-4dff-ab50-762c43ae751e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor(label=target_col).fit(df_train, num_cpus=12, num_gpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388159c1-fce5-4df5-a385-3934b91d99f7",
   "metadata": {},
   "source": [
    "We can also evaluate the performance of each individual trained model on our (labeled) test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3b7e1-2757-4b8a-b6d1-e1e4643c8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(df_test, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01571119-c8b3-49c3-bc12-1fad6d2de3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310e4da-e5de-4b8a-a17d-0756c9560a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(df_test)\n",
    "predictor.predict_proba(df_test)\n",
    "predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa62e05-a309-4fe8-b732-b6101b09fa6e",
   "metadata": {},
   "source": [
    "Above the scores of predictive performance were based on a default evaluation metric (accuracy for binary classification). Performance in certain applications may be measured by different metrics than the ones AutoGluon optimizes for by default. If you know the metric that counts in your application, you should specify it as demonstrated in the next section.\r\n",
    "\r\n",
    "## Presets\r\n",
    "\r\n",
    "AutoGluon comes with a variety of presets that can be specified in the call to `.fit` via the `presets` argument. `medium_quality` is used by default to encourage initial prototyping, but for serious usage, the other presets should be used instead.\r\n",
    "\r\n",
    "| Preset                            | Model Quality                                          | Use Cases                                                                                                                                               | Fit Time (Ideal) | Inference Time (Relative to medium_quality) | Disk Usage |\r\n",
    "|:----------------------------------|:-------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------|:--------------------------------------------|:-----------|\r\n",
    "| best_quality                      | State-of-the-art (SOTA), much better than high_quality | When accuracy is what matters                                                                                                                           | 16x+             | 32x+                                        | 16x+       |\r\n",
    "| high_quality                      | Better than good_quality                               | When a very powerful, portable solution with fast inference is required: Large-scale batch inference                                                    | 16x              | 4x                                          | 2x         |\r\n",
    "| good_quality                      | Significantly better than medium_quality               | When a powerful, highly portable solution with very fast inference is required: Billion-scale batch inference, sub-100ms online-inference, edge-devices | 16x              | 2x                                          | 0.1x       |\r\n",
    "| medium_quality                    | Competitive with other top AutoML Frameworks           | Initial prototyping, establishing a performance baseline                                                                                                | 1x               | 1x                                          | 1x         |\r\n",
    "\r\n",
    "We recommend users to start with `medium_quality` to get a sense of the problem and identify any data related issues. If `medium_quality` is taking too long to train, consider subsampling the training data during this prototyping phase.  \r\n",
    "Once you are comfortable, next try `best_quality`. Make sure to specify at least 16x the `time_limit` value as used in `medium_quality`. Once finished, you should have a very powerful solution that is often stronger than `medium_quality`.  \r\n",
    "Make sure to consider holding out test data that AutoGluon never sees during training to ensure that the models are performing as expected in terms of performance.  \r\n",
    "Once you evaluate both `best_quality` and `medium_quality`, check if either satisfies your needs. If neither do, consider trying `high_quality` and/or `good_quality`.  \r\n",
    "If none of the presets satisfy requirements, refer to [tutorials/tabular_prediction/tabular-indepth.ipynb](https://github.com/gidler/autogluon-tutorials/blob/main/tutorials/tabular_prediction/tabular-indepth.ipynb) for more advanced Aally use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afec0c2-4cc9-42eb-bd26-59f45b7ddd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit = 60  \n",
    "metric = 'roc_auc'  \n",
    "predictor = TabularPredictor(target_col, eval_metric=metric).fit(df_train, time_limit=time_limit, presets='best_quality')\n",
    "predictor.leaderboard(df_test, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46154e22-8b9c-4c60-9e60-5a3c989e4307",
   "metadata": {},
   "source": [
    "This command implements the following strategy to maximize accuracy:\r\n",
    "\r\n",
    "- Specify the argument `presets='best_quality'`, which allows AutoGluon to automatically construct powerful model ensembles based on [stacking/bagging](https://arxiv.org/abs/2003.06505), and will greatly improve the resulting predictions if granted sufficient training time. The default value of `presets` is `'medium_quality'`, which produces *less* accurate models but facilitates faster prototyping. With `presets`, you can flexibly prioritize predictive accuracy vs. training/inference speed. For example, if you care less about predictive performance and want to quickly deploy a basic model, consider using: `presets=['good_quality', 'optimize_for_deployment']`.\r\n",
    "\r\n",
    "- Provide the parameter `eval_metric` to `TabularPredictor()` if you know what metric will be used to evaluate predictions in your application. Some other non-default metrics you might use include things like: `'f1'` (for binary classification), `'roc_auc'` (for binary classification), `'log_loss'` (for classification), `'mean_absolute_error'` (for regression), `'median_absolute_error'` (for regression).  You can also define your own custom metric function.  For more information refer to [tutorials/tabular_prediction/tabular-custom-metric.ipynb](https://github.com/gidler/autogluon-tutorials/blob/main/tutorials/tabular_prediction/tabular-custom-metric.ipynb)\r\n",
    "\r\n",
    "- Include all your data in `train_data` and do not provide `tuning_data` (AutoGluon will split the data more intelligently to fit its needs).\r\n",
    "\r\n",
    "- Do not specify the `hyperparameter_tune_kwargs` argument (counterintuitively, hyperparameter tuning is not the best way to spend a limited training time budgets, as model ensembling is often superior). We recommend you only use `hyperparameter_tune_kwargs` if your goal is to deploy a single model rather than an ensemble.\r\n",
    "\r\n",
    "- Do not specify `hyperparameters` argument (allow AutoGluon to adaptively select which models/hyperparameters to use).\r\n",
    "\r\n",
    "- Set `time_limit` to the longest amount of time (in seconds) that you are willing to wait. AutoGluon's predictive performance improves the longer `fit()` is alle other features:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
