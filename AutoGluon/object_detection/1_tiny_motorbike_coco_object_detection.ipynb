{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400ce743-856d-470b-beb8-b145a51e1650",
   "metadata": {},
   "source": [
    "# AutoMM Detection\n",
    "\n",
    "Our goal is to fast finetune a pretrained model on a dataset in COCO format, and evaluate on its test set. Both training and test sets are in COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8428d4-62d2-481a-a0ac-2cdd47866d68",
   "metadata": {},
   "source": [
    "We using COCO format dataset, the input is the json annotation file of the dataset split. In this example, trainval_cocoformat.json is the annotation file of the train-and-validate split, and text_cocoformat.json is annotation file of the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a88c84-4513-4485-bba0-e7f8d6b7b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(download_dir, \"tiny_motorbike\")\n",
    "train_path = os.path.join(data_dir, \"Annotations\", \"trainval_cocoformat.json\")\n",
    "test_path = os.path.join(data_dir, \"Annotations\", \"test_cocoformat.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679276a-09ce-442b-b029-9e92caf9f3b8",
   "metadata": {},
   "source": [
    "## Creating the MultiModalPredictor\n",
    "\n",
    "We select the `\"medium_quality\"` presets, which uses a YOLOX-large model pretrained on COCO dataset. This preset is fast to finetune or inference,\r\n",
    "and easy to deploy. We also provide presets `\"high_quality\"` with a DINO-Resnet50 model and `\"best quality\"` with a DINO-SwinL model, with much higher performance but also slower and with higher GPU memory usage.ovide presets high_quality with a DINO-Resnet50 model and best_quality with a DINO-SwinL model, with much hgiher performance but also slower and with higher GPU memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be37dc-2b82-4427-b942-3ed89c1f62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "presets = 'medium_quality'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce66ab6-5b6f-47d3-8351-1656e53d7b22",
   "metadata": {},
   "source": [
    "We create the MultiModalPredictor with selected presets. \n",
    "We need to specify the problem_type to `\"object_detection\"` \r\n",
    "and also provide a `sample_data_path` for the predictor to infer the catgories of the datase .\r\n",
    "Here we provide the `train_path`, and it also works using any other split of this datas t.\r\n",
    "And we also provide a `path` to save the predic r. \r\n",
    "It will be saved to a automatically generated directory with timestamp under `AutogluonModels` if `path` is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a798f4-7e20-4f09-b6bb-b9437fdfa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor(\n",
    "    problem_type=\"object_detection\",\n",
    "    sample_data_path=train_path,\n",
    "    presets=presets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6416cc-6c69-4a55-a740-3e9797b4ed9e",
   "metadata": {},
   "source": [
    "## Finetuning the Model\r\n",
    "\r\n",
    "Learning rate, number of epochs, and batch_size are included in the presets, and thus no need to specif .\r\n",
    "Note that we use a two-stage learning rate option during finetuning by defau t,\r\n",
    "and the model head will have 100x learning r te.\r\n",
    "Using a two-stage learning rate with high learning rate only on head layers  akes\r\n",
    "the model converge faster during finetuning. It usually gives better performance as well,\r\n",
    "especially on small datasets with hundreds or thousands of  mages.\r\n",
    "We also com ute the time of the fit process here for better understanding thown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7726dc-0955-499c-bb19-d28279137ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit(train_path)  # Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f7e1d-ae23-4620-9af0-0d541f8d2724",
   "metadata": {},
   "source": [
    "## Evaluation\r\n",
    "\r\n",
    "To evaluate the model we just trained, run following code.\r\n",
    "\r\n",
    "And the evaluation results are shown in command line output. \r\n",
    "The first line is mAP in COCO standard, and the second line is mAP in VOC standard (or mAP50).  Note that for presenting a fast finetuning we use presets \"medium_quality\", you could get better result on this dataset by simply using \"high_quality\" or \"best_quality\" presets, \r\n",
    "or customize your own model and hyperparameter settings.atne_coco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25727d28-0f3a-4992-9fb1-5bba5d5890f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274433f1-d358-4508-8aea-f408bc9335d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictor.predict(test_path, save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a97801-46ea-40f6-922b-03d95402086e",
   "metadata": {},
   "source": [
    "## Visualizing Results\n",
    "\n",
    "To visualize the detection bounding boxes, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222e6b0-cd44-487f-b737-6bf56ab34a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal.utils import ObjectDetectionVisualizer\n",
    "\n",
    "conf_threshold = 0.4  # Specify a confidence threshold to filter out unwanted boxes\n",
    "image_result = pred.iloc[30]\n",
    "\n",
    "img_path = image_result.image  # Select an image to visualize\n",
    "\n",
    "visualizer = ObjectDetectionVisualizer(img_path)  # Initialize the Visualizer\n",
    "out = visualizer.draw_instance_predictions(image_result, conf_threshold=conf_threshold)  # Draw detections\n",
    "visualized = out.get_image()  # Get the visualized image\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "img = Image.fromarray(visualized, 'RGB')\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a40514-f975-4973-b9ff-981270c246f3",
   "metadata": {},
   "source": [
    "## Testing on Your Own Data\n",
    "You can also predict on your own images with various input format. The follow is an example:\n",
    "\n",
    "Download the example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f4d3f-447a-4d07-9ecd-c95a78f5ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import download\n",
    "image_url = \"https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/detection/street_small.jpg\"\n",
    "test_image = download(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c45dae-ccb9-410b-bffb-025ad5e86fe3",
   "metadata": {},
   "source": [
    "Run inference on data in a json file of COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865c7ec-75cb-4409-8b31-4388ef8c4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# create a input file for demo\n",
    "data = {\"images\": [{\"id\": 0, \"width\": -1, \"height\": -1, \"file_name\": test_image}], \"categories\": []}\n",
    "os.mkdir(\"input_data_for_demo\")\n",
    "input_file = \"input_data_for_demo/demo_annotation.json\"\n",
    "with open(input_file, \"w+\") as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "pred_test_image = predictor.predict(input_file)\n",
    "print(pred_test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d90e1-8da6-46e4-afd8-2b3c9a1ee94c",
   "metadata": {},
   "source": [
    "Run inference on data in a list of image file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d1817-574d-4666-8da6-d539bd2fe994",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_threshold = 0.4  # Specify a confidence threshold to filter out unwanted boxes\n",
    "image_result = pred_test_image.iloc[0]\n",
    "\n",
    "img_path = image_result.image  # Select an image to visualize\n",
    "visualizer = ObjectDetectionVisualizer(img_path)  # Initialize the Visualizer\n",
    "out = visualizer.draw_instance_predictions(image_result, conf_threshold=conf_threshold)  # Draw detections\n",
    "visualized = out.get_image()  # Get the visualized image\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "img = Image.fromarray(visualized, 'RGB')\n",
    "display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
